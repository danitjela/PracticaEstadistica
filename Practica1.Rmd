---
title: 'Práctica Estadística Descriptiva- GRUPO 9'
author: "RAÚL BENÍTEZ TIBURÓN, ESTER DÍAZ MONZONIS, AROA QUIROGA MARTÍNEZ, SANDRA SÁEZ PIÑA, DANIELA TOCINO JIMÉNEZ"
date: "Estadística - Curso 2024/2025"

output: 
  bookdown::html_document2:
    toc: yes
    toc_float: yes
  # bookdown::pdf_document2:
  #   includes:
  #     in_header: preamble.tex
---

```{r setup, include=FALSE, purl=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      eval = TRUE, 
                      warning = FALSE,
                      message = FALSE,
                      error = TRUE)
``` 

# Introducción y definición de objetivos

El archivo Steam_2024_bestRevenue_1500.csv contiene una recopilación de datos de los 1500 juegos con más beneficios obtenidos, concretamente, lanzados en Steam desde el 1 de enero de 2024, hasta el 9 de septiembre de 2024.

El principal objetivo de nuestro estudio estadístico es dar respuesta a una serie de preguntas, y conocer las distintas relaciones existentes entre la recaudación de varios videojuegos y las diferentes variables que puedan llegar a afectar a este indicador.

En cuanto a las preguntas, hemos planteado las siguientes:

`- ¿Los indies recaudan más dinero que los AA o AAA?`

`- ¿Los juegos que venden más copias recaudan más dinero?`

`- ¿Los juegos más caros recaudan más dinero que los baratos?`

`- ¿Los juegos más largos recaudan más dinero que los que son más cortos?`

`- ¿Los juegos con buenas valoraciones recaudan más que los que tienen peor puntuación?`

También cabe mencionar que, el estudio de la variable "reviewScore" nos ha llamado la atención al observar que gran cantidad de los juegos tienen una valoración de 0, lo cual puede significar que, a la hora de cargar los datos en la página del dataset, ha podido haber algún error.

Además, vamos a descartar del estudio la variable "steamId", ya que no nos aporta ningún tipo de información relevante para nuestro objetivo.


# Importación de datos y carga de paquetes

Para comenzar nuestro análisis descriptivo, necesitamos cargar una serie de paquetes en R que facilitarán la manipulación de datos, la creación de gráficos, y la presentación de tablas. Estos paquetes incluyen 'tidyverse' para la manipulación de datos, 'summarytools' y 'corrplot' para análisis estadísticos, 'GGally' para gráficos de pares, 'gt' y 'flextable' para tablas avanzadas, 'knitr' para la integración de R con documentos de texto, 'dplyr' para la modificación de los datos en un data frame.

```{r}

library(tidyverse)
library(summarytools)
library(GGally)
library(gt)
library(flextable)
library(knitr) 
library(corrplot)
library(dplyr)
library(kableExtra)

```

A continuación, leeremos y almacenaremos los datos de nuestro estudio. Para ello, utilizamos el método read.csv(), al cual le introducimos como parámetros: la ruta relativa del archivo, se especifica que el archivo tiene una fila de encabezados para los nombres de las variables y el tipo de separación de los elementos en el archivo (en nuestro caso commas). El resultado de esta operación se almacena en la variable lab con la que trabajaremos durante el análisis.

```{r, results = 'hide'}

  lab <- read.csv("DATA/Steam_2024_bestRevenue_1500.csv", header = TRUE, sep = ",")
  lab |>
  mutate(releaseDate = as.Date(releaseDate))
  
```


# Diccionario de datos

En esta sección, presentamos un diccionario de datos que detalla cada variable contenida en nuestro conjunto de datos 'Steam_2024_bestRevenue_1500.csv'. Las variables abarcan desde el nombre de cada uno de los juegos, hasta los desarrolladores de cada uno de ellos.


* `name`: Nombre del juego.
    - Variable tipo: Identificador.
      
* `releaseDate`: Fecha de salida del juego ("DD/MM/AAAA").
    - Variable tipo: Marca de tiempo.
      
* `copiesSold`: Número de copias vendidas (Unidades).
    - Variable tipo: Cuantitativa / Discreta.
      
* `price`: Precio original del juego de salida ($).
    - Variable tipo: Cuantitativa / Continua
      
* `revenue`: Cantidad de dinero recaudada por el juego ($).
    - Variable tipo: Cuantitativa / Continua
      
* `avgPlaytime`: Tiempo medio que los jugadores han empleado en el juego (Horas).
    - Variable tipo: Cuantitativa / Continua.
      
* `reviewScore`: Puntuación del juego en Steam (0-100).
    - Variable tipo: Cuantitativa / Discreta.
      
* `publisherClass`: Se definen las empresas como pequeña (indie), mediana (AA) o grande (AAA).
    - Variable tipo: Cualitativa / Multinivel.
      
* `publishers`: Empresa que se dedica a la publicación y marketing del juego.
    - Variable tipo: Identificador.
      
* `developers`: Empresa que se dedica a desarrollar y mantener el juego.
    - Variable tipo: Identificador.
      
* `steamId`: Id de Steam
    - Variable tipo: Identificador.
      
    
# Muestra del dataset

Ahora, vamos a echar un vistazo a las primeras filas de nuestro dataset para obtener una comprensión inicial de los datos con los que estamos trabajando. 

```{r}

lab |>  
  slice_head(n=10) |> 
  gt()

```


# Análisis exploratorio de datos

## Datos univariantes

Comenzaremos nuestro análisis exploratorio de datos con un enfoque en los datos univariantes. Este enfoque nos permite entender la distribución y frecuencia de cada variable individualmente.

### Estudio de la variable RELEASEDATE

Para el estudio de la variable "releaseDate" crearemos un histograma, donde se agruparán las fechas de salida de cada videojuego en meses (desde enero hasta septiembre de este mismo año), y determinaremos cuál han sido los con más y menos lanzamientos.

```{r}
lab <- lab |> 
  mutate(releaseDate = as.Date(releaseDate, format = "%d-%m-%Y"))

lab <- lab |> 
  mutate(mes = format(releaseDate, "%m"), 
         mes = factor(mes, levels = sprintf("%02d", 1:12), labels = month.abb))

lanzamientos_mes <- lab |> 
  group_by(mes) |> 
  summarise(n_juegos = n(), .groups = 'drop')

  ggplot(lanzamientos_mes, aes(x = mes, y = n_juegos, fill = n_juegos)) +
    geom_bar(stat = "identity", color = "white", alpha = 0.8) +
    scale_fill_gradient2(low = "steelblue", mid = "skyblue", high = "red", midpoint = median(lanzamientos_mes$n_juegos)) +
    theme_bw() +
    labs(title = "Distribución de las fechas de lanzamiento del 2024",
         x = "Mes",
         y = "Nº Lanzamientos")
```


Según el gráfico podemos decir que los meses con más lanzamientos han sido: 1º -> Mayo, 2º -> Abril, 3º -> Marzo. Mientras tanto los meses con menos lanzamientos han sido: 1º -> Septiembre (ya que los datos van desde principios de este año hasta el 9 de septiembre), 2º -> Enero, 3º -> Agosto.


### Estudio de la variable COPIESSOLD

Primero, generamos una tabla de frecuencias y un histograma agrupando la variable 'copiesSold' por intervalos, esto nos ayuda a entender cuántas copias han sido vendidas de cada juego en toda nuestra muestra, si hay concentraciones de valores o si hay posibles outliers. 

```{r}

  copiesSold_breaks <- c(500, 5000, 10000, 15000, 25000, 50000, 100000, 1000000, 5000000, 10000000, 31000000)
  copiesSold_labels <- c("[500-5k]", "(5k-10k]", "(10k-15k]", "(15k-25k]", "(25k-50k]", "(50k-100k]", "(100k-1M]", "(1M-5M]", "(5M-10M]", "(10M-31M]")

  lab$copiesSold_intervalos <- cut(lab$copiesSold, breaks = copiesSold_breaks, labels = copiesSold_labels, include.lowest = TRUE)

  
  table(lab$copiesSold_intervalos) |> 
  
  as.data.frame() |> 

  mutate(freqRelativa = Freq / sum(Freq), freqAbsAcumulada = cumsum(Freq), freqRelAcumulada = cumsum(freqRelativa)) |>
  
  gt() |> 

  tab_header(
    title = md("**_Nº de copias vendidas_**")
  ) |>
  
  cols_label(Var1 = "\\(x_i\\)", Freq = "\\(n_i\\)", freqRelativa = "\\(f_i\\)", 
  freqAbsAcumulada = "\\(N_i\\)", freqRelAcumulada = "\\(F_i\\)") |>  
  
  fmt_number(3, decimals = 4) |> 

  tab_style(style = list (cell_text(weight = "bold")), locations = cells_column_labels()) |>

  tab_style(style = list(cell_text(weight = "bold")),  locations = cells_body(rows = c(1, 2))) 
  
```
Analizando las frecuencias podemos ver cómo casi la mitad del peso de las muestras se concentran en los primeros intervalos hasta los 5M de ventas, por lo que podemos asumir una desviación de las muestras hacia la izquierda y un sesgamiento general de los datos.

```{r} 
  ggplot(data.frame(x = lab$copiesSold), aes(x = x)) +
  geom_histogram(binwidth = 200000, fill = "steelblue", color = "white", 
                 aes(y = ..count..)) +
  theme_bw() +
  labs(title = "Distribución del Nº de copias vendidas:",
       x = "Precio ($)",
       y = expression("Frecuencia absoluta ("*n[i]*")")) +

  scale_x_continuous(limits = c(500, 6000000), 
                     breaks = seq(1000000, 6000000, by = 1000000),
                     labels = c("1M", "2M", "3M", "4M", "5M", "6M")) +
  scale_y_continuous(limits = c(0, 130), 
                     breaks = seq(0, 130, by = 20),
                     labels = seq(0, 130, by = 20))

```


```{r}

  ggplot(lab, aes(x = copiesSold)) +
  geom_histogram(binwidth = 200000, fill = "steelblue", color = "white", 
                 aes(y = ..count../sum(..count..))) +
  stat_function(fun = dnorm, args = list(mean = mean(lab$copiesSold), 
                sd = sd(lab$copiesSold)), color = "red", size = 1.5, alpha = 0.6) +
  theme_bw() +
  labs(title = "Distribución del Nº de copias vendidas:",
       x = "Precio ($)",
       y = expression("Frecuencia relativa ("*f[i]*")")) +
  
  scale_x_continuous(limits = c(0, 6000000), 
                     breaks = seq(1000000, 6000000, by = 1000000),
                     labels = c("1M", "2M", "3M", "4M", "5M", "6M")) +
  scale_y_continuous(limits = c(0, 0.025), 
                     breaks = seq(0, 0.025, by = 0.01),
                     labels = seq(0, 0.025, by = 0.01))
```


Con el fin de facilitar el análisis del gráfico, a continuación se muestra un resumen numérico de la variable `copiesSold`:

```{r}
  lab|> select(copiesSold) |> descr() |> kable(digits = 2)
```

Según todos los datos y gráficos recabados en el análisis de esta variable, confirmamos que los datos de las ventas están sesgados, concretamente dicha distribución de ventas se encuentra sesgada hacia la derecha (cola derecha), esto se debe a que la media es más alta que la mediana (Mean = 141482.57 // Median = 11928.50) y al coeficiente de asimetría positivo (Skewness	= 18.58). Además, comparado con una distribución normal, podemos asegurar a través de su curtosis (Kurtosis =	419.44) que nuestra muestra es extremadamente más alta (idealmente Kurtosis =	3.00) y con colas extremadamente largas, por lo que tiene sentido que la representación de la distribución normal de los datos se comporte como una línea recta y no se asemeje para nada a una campana.

Tal y como estaba previsto, se trata de una distribución con pocos valores significativos y muchos outliers que alteran la medición de los datos y no aportan prácticamente ningún valor al análisis; aun así, resulta interesante saber que aproximadamente la mitad del peso de las ventas de la muestra se concentran entre las primeras 10 mil ventas y que el mínimo de ventas ha sido 593 y el máximo ha sido 30739148, lo cual énfatiza el amplio rango de datos de esta variable.

### Estudio de la variable PRICE

Para el estudio de 'price', crearemos una tabla de frecuencias y un histograma, proporcionando una visión clara de cuánto cuesta una copia de cada juego para así, descartar posibles outliers y hacer un análisis más preciso.

```{r}

  price_breaks <- seq(min(lab$price), max(lab$price), length.out = 11)
  lab$price_intervalos <- cut(lab$price, breaks = price_breaks, include.lowest = TRUE)

  table(lab$price_intervalos) |> 

  as.data.frame() |> 

  mutate(freqRelativa = Freq / sum(Freq), freqAbsAcumulada = cumsum(Freq), freqRelAcumulada = cumsum(freqRelativa)) |>

  gt() |> 

  tab_header(
    title = md("**_Precio por copia ($)_**")
  ) |>

  cols_label(Var1 = "\\(x_i\\)", Freq = "\\(n_i\\)", freqRelativa = "\\(f_i\\)", 
  freqAbsAcumulada = "\\(N_i\\)", freqRelAcumulada = "\\(F_i\\)") |>  

  fmt_number(3, decimals = 4) |> 

  tab_style(style = list (cell_text(weight = "bold")), locations = cells_column_labels())
  
```

Como se puede apreciar, predominan los precios entre los 0 y 30 dólares, siendo mucho más frecuentes entre los mismos los precios entre los 10 y los 20 dólares, representando aproximadamente algo más de un tercio del peso de la muestra (42%). Asimismo, el siguiente intervalo más frecuente es el de los 0 a 10 dólares, con un peso del 33% de la muestra. 

Cabe destacar como posible outlier el único precio con una frecuencia de 1 que se corresponde con el valor de 99,99$, por lo que se excluirá este valor a la hora de representar los valores en el histograma.

```{r}
  lab_filtrado <- lab[lab$price != 99.99,]
  price_filtrado <- lab_filtrado$price

```


```{r}

  ggplot(data.frame(x = price_filtrado), aes(x = x)) +
  geom_histogram(binwidth = 3, fill = "steelblue", color = "white", 
                 aes(y = ..count..)) +
  theme_bw() +
  labs(title = "Distribución del precio por copia:",
       x = "Precio ($)",
       y = expression("Frecuencia absoluta ("*n[i]*")"))
```

```{r}

  ggplot(data.frame(x = price_filtrado), aes(x = x)) +
  geom_histogram(binwidth = 5, fill = "steelblue", color = "white", 
                 aes(y = ..count../sum(..count..))) +
  stat_function(fun = dnorm, args = list(mean = mean(price_filtrado), 
                sd = sd(price_filtrado)), color = "red", size = 1.5, alpha = 0.6) +
  theme_bw() +
  labs(title = "Distribución del precio por copia:",
       x = "Precio ($)",
       y = expression("Frecuencia relativa ("*f[i]*")"))
```

Con el fin de facilitar el análisis del gráfico y de poder comprobar cómo ha cambiado la precisión del analisis sin el outlier mencionado anteriormente, a continuación se muestra un resumen numérico de la variable `price` y de la misma filtrada :

```{r}
  analisis_price <- lab|> select(price) |> descr() |> kable(digits = 2)
  analisis_price_filtrado <- price_filtrado |> descr() |> kable(digits = 2)

  cbind(analisis_price, analisis_price_filtrado) |> 
  kable(digits = 2)

```

Según todos los datos y gráficos recabados en el análisis de esta variable, podemos concluir con que efectivamente los precios están muy dispersos alrededor de la media (Mean = 17.46 // Std. Dev = 12.47), concretamente dicha distribución de precios se encuentra sesgada hacia la derecha (cola derecha), esto se debe a que la media es más alta que la mediana (Mean = 17.46 // Median = 14.99) y al coeficiente de asimetría positivo (Skewness = 1.46).

En definitiva, podemos obtener varias conclusiones de este estudio: hay una clara tendencia hacia los precios menores en nuestra muestra y además, hemos encontrado valores que distorsionan los datos.


### Estudio de la variable REVENUE

Analizamos la variable "revenue" mediante un histograma de los beneficios que nos muestra la distribución de los beneficios que obtienen estos videojuegos.

```{r}
ggplot(lab, aes(x = revenue)) +

  geom_histogram(binwidth = 2000000, fill = "steelblue", color = "white") +

  labs(title = "Distribución de los Beneficios de los Videojuegos",

       x = "Beneficios ($)",
       y = "Frecuencia") +

  ylim(0, 200) +  # Establece el rango del eje Y de 0 a 500
  xlim(0, 50000000) +  # Limita el rango del eje X a 50 millones

  theme_minimal() + 

  scale_x_continuous(limits = c(0, 50000000),
    breaks = seq(10000000, 50000000, by = 10000000),
    labels = c("10M", "20M", "30M", "40M", "50M"))

```


En este histograma vemos la alta concentración de videojuegos con bajos beneficios, son menos frecuentes los juegos que alcanzan beneficios entre los 10 y los 50 millones. La gráfica muestra una clara asimetría con la cantidad que ganan poco y los pocos que obtienen grandes ingresos.


### Estudio de la variable AVGPLAYTIME

A continuación, nos enfocamos en el tiempo que dedican las personas a cada uno de los juegos.
Una herramienta crucial para entender la distribución de nuestra variable cuantitativa es el histograma, ya que este gráfico nos permitirá observar la forma y la dispersión de los datos.

Vamos a utilizar el color 'steelblue' para las barras, lo que nos permite observar la distribución de la variable de manera sencilla.

```{r}

lab |> ggplot(aes(avgPlaytime)) +
  
  geom_histogram(
    
    fill = "steelblue", 
             
    col = "white",    
    breaks = seq(0,100, by = 10)
  ) +

  theme_bw() +
    labs(x = "Tiempo promedio de juego (horas)", y = "Frecuencia", title = "Distribución de tiempo de juego por   intervalos")

```


Si analizamos el histograma se puede observar que la mayoría de los jugadores dedican menos de 10 horas a los videojuegos. Hay una caída significativa en la frecuencia de jugadores que juegan más de 10 horas, lo que sugiere que pocos jugadores le dedican tanto tiempo al juego. Esto puede indicar que muchos juegos no requieren un compromiso prolongado, o que los jugadores tienden a jugar varios titulos en sesiones cortas de tiempo.


A continuación, se crea una tabla de con los juegos que tienen más horas promedio jugadas.

```{r}

top_ten_games <- lab %>%
  arrange(desc(avgPlaytime)) %>%  
  slice(1:10) %>%                  
  select(name, avgPlaytime) %>%    
  mutate(avgPlaytime = round(avgPlaytime, 2))  


top_ten_games |> 
  kable(caption = "Los 10 juegos con más horas de juego") |> 
  kable_styling(full_width = F)

```

### Estudio de la variable REVIEWSCORE

```{r}

num_respuestas_SCORE <- length(unique(lab$reviewScore))
cat("La cantidad de respuestas obtenidas es:", num_respuestas_SCORE)

```


Esta variable la estudiaremos para poder ver más adelante si se puede relacionar con la recaudación de los juegos. A continuación, con el siguiente código esudiaremos las frecuencias relativas y absolutas por rangos debido a la cantida de valores que hay.

```{r}

max_val <- max(lab$reviewScore)
max_val <- min(max_val, 100)
lab$reviewScore_rango <- cut(lab$reviewScore, 
                             breaks = c(0, 1, seq(5, max_val, by = 5)),
                             right = FALSE, 
                             include.lowest = TRUE,
                             labels = c("0", paste(seq(1, max_val-4, by = 5), seq(5, max_val, by = 5)-1, sep = "-")))
tabla_frecuencias_score <- lab |>
  count(reviewScore_rango) |>
  mutate(f = n / nrow(lab), N = cumsum(n), F = cumsum(f))
tabla_frecuencias_ordenada4 <- tabla_frecuencias_score |> 
  arrange(desc(n))
tabla_frecuencias_ordenada4$F <- cumsum(tabla_frecuencias_ordenada4$f)
tabla_frecuencias_ordenada4$N <- cumsum(tabla_frecuencias_ordenada4$n)
print(tabla_frecuencias_ordenada4)

```


Como se puede observar hay bastantes valores de 0 que como hemos comentado debe tratarse de un error. Por ello, lo hemos sacado fuera de los rangos y para continuar con el estudio, eliminaremos ese valor para poder realizarlo de una manera más fiel a la realidad. Para esto, utilizaremos el siguiente código.

```{r}

labNo0 <- subset(lab, reviewScore != 0)

```


A continuación, realizaremos un histograma mediante el siguiente código.

```{r}

datos <- labNo0$reviewScore 
ggplot(data.frame(x = datos), aes(x = x)) +
  geom_histogram(binwidth = 1, fill = "steelblue", color = "white", 
                 aes(y = ..density..), alpha = 0.6) +
  stat_function(fun = dnorm, args = list(mean = mean(datos), 
                                         sd = sd(datos)), color = "red", size = 1.5) +
  labs(title = "Distribución de las puntuaciones",
       x = "Puntuación",
       y = "Frecuencia") 

```


Además de este histograma, debemos realizar un resumen númerico a partir del cual podremos comprender los gráficos con facilidad.

```{r}

labNo0 |> select(reviewScore) |> descr() |> kable(digits = 2)

```


Podemos observar como las puntuaciones por lo general, son extremadamente altas. Esto se puede deber a que el dataset es sobre los 1500 mejores juegos según su recaudación, por lo que podemos entender que son buenos juegos. Además, estas valoraciones son puestas por los usuarios y no por críticos profesionales.

### Estudio de la variable PUBLISHERCLASS

Ahora analizaremos la variable "publisherclass". En esta variable, veremos las diferencias entre los tipos de empresas que hay y como se distribuyen. A continuación, con el siguiente código estudiaremos las frecuencias relativas y absolutas.

```{r}

tabla_frecuencias_publisherclass <- lab |>
  count(publisherClass) |>
  mutate(f = n / nrow(lab)) 

print(tabla_frecuencias_publisherclass)

```


Para observar estos datos con mayor claridad, utilizaremos una gráfica en función de la frecuencia relativa con el siguiente código.

```{r}

lab  |> group_by(publisherClass) |>  summarise(Frequency = n()) |> mutate(Frequency = Frequency/sum(Frequency), publisherClass = reorder(publisherClass, -Frequency)) |> ggplot(aes(x = publisherClass, y = Frequency)) + geom_bar(stat = "identity", aes(fill = Frequency)) + scale_y_continuous(labels = scales::percent) + theme_bw() + labs(title = "Gráfico de barras con frecuencia relativa de PUBLISHERCLASS", x = "Tipo de empresa", y = "Frecuencia relativa") + scale_fill_gradient("Frecuencia", low = "steelblue", high = "#CB0017") + theme(axis.text.x = element_text(angle = 45, hjust = 1))

```


Como podemos observar, la mayor parte de los valores obtenidos, son del tipo "Indie", que es como se denota la empresa pequeña, ocupando el 87% de los casos. Además, se puede observar un caso asilado, "Hobbyist", que es como se denota a un particular que hace el juego por afición.  


### Estudio de la variable PUBLISHERS

A continuación analizamos la variable "publishers" mediante un gráfico de barras que muestra la frecuencia de los 10 publishers más representativos según la cantidad de juegos publicados en Steam. Primero contamos los videojuegos por publisher y seleccionamos los 10 más comunes y luego creamos en gráfico de barras con esos datos.

```{r}

top_publishers <- lab %>%

  count(publishers) %>%

  top_n(10, n)  

ggplot(top_publishers, aes(x = reorder(publishers, n), y = n)) +

  geom_bar(stat = "identity", fill = "steelblue", color = "white") +

  labs(title = "Top 10 Publishers por Número de Videojuegos",

       x = "Publisher",
       y = "Número de Videojuegos") +

  theme_minimal() +
  coord_flip()  

```


En esta gráfica podemos ver los 10 publishers que tienen una influencia notable en Steam debido al volumen de títulos publicados.

### Estudio de la variable DEVELOPERS


Ahora vamos a analizar la variable "developers". 
Realmente para nuestro estudio no es de gran importancia, aun así, crearemos una tabla de frecuencia para saber cuales son los 10 desarrolladores más frecuentes, ya que, puede ser curioso saberlo. 

```{r}

table(lab$developers) |> 
  as.data.frame() |> 
  
  arrange(desc(Freq)) |> 
  slice(1:10) |> 
  mutate(F = cumsum(Freq)/sum(Freq)) |> 
  gt() |>  
  
  tab_header(
    title = md("**_Los 10 desarrolladores más frecuentes_**")
  ) |>
  
  cols_label(Var1 = "Desarrollador",  
             Freq = "Frecuencia",  
             F = "Frecuencia relativa acumulada") |>  
  
  fmt_number(3, decimals = 4) |> 
  tab_style(style = list(
    cell_text(weight = "bold")),  
    locations = cells_column_labels())

```

En la tabla podemos observar claramente los 10 desarrolladores más frecuentes entre los 1407 desarrolladores únicos.
Como ya hemos mencionado, esta variable no será de gran importancia a la hora de responder a nuestras preguntas y de cumplir nuestro objetivo final de la práctica.


## Datos bivariantes

### Gráfico de correlación numérica

```{r}
labNo0 |> select(copiesSold, revenue, price, reviewScore, avgPlaytime) |> 
  cor() |> 
  corrplot(method = "ellipse",  # Usa elipses para representar correlaciones
           type = "lower",  # Muestra solo la mitad inferior de la matriz
           addCoef.col = "steelblue",  # Color de los coeficientes de correlación
           diag = FALSE)  # Omite la diagonal principal
```

Aunque la única relación notable que puede haber es la recaudación con el número de copias vendidas, hemos decidido realizar un análisis bivariante entre recaudación con el resto de variables, ya que es el objetivo de nuestro estudio.

### Estudio de las variables COPIESSOLD Y REVENUE

Antes de comenzar con el analisis bivariante de "copiesSold" y "revenue" vamos a hacer un resumen de ambas variables para saber la cantidad de copias vendidas y la recaudación promedio, los valores mínimos y máximos, o los valores faltantes en caso de que los haya. Esto se hace con el objetivo de conocer mejor sus valores y distribución.

```{r}

sum(is.na(lab$copiesSold))
sum(is.na(lab$revenue))

summary(lab$copiesSold)
summary(lab$revenue)
```

A continuación, vamos a realizar un gráfico de dispersión para así saber si hay una relación visual en ambas variables.
```{r}
ggplot(lab, aes(x = copiesSold, y = revenue)) +
  geom_jitter(color = "blue", size = 1, width = 0.2, height = 0, alpha = 0.7) +
  scale_y_continuous(labels = function(x) {
    ifelse(x >= 1e6, 
           paste0(format(x / 1e6, big.mark = ",", digits = 2), " M"),
           ifelse(x >= 1e3, 
                  paste0(format(x / 1e3, big.mark = ",", digits = 2), " K"), 
                  format(x)))
  }) +
  scale_x_continuous(labels = function(x) {
    ifelse(x >= 1e6, 
           paste0(format(x / 1e6, big.mark = ",", digits = 2), " M"),
           ifelse(x >= 1e3, 
                  paste0(format(x / 1e3, big.mark = ",", digits = 2), " K"), 
                  format(x)))
  }) +
  labs(title = "Relación entre Copias Vendidas y Recaudación",
       x = "Copias Vendidas",
       y = "Recaudación (en logaritmos)") +
  theme_minimal()
```


Tras esto, calcularemos la correlación entre "copiesSold" y "revenue" para determinar si su relación es fuerte o débil, y representaremos el resultado en forma de tabla.

```{r}
correlacion <- cor(lab$copiesSold, lab$revenue, use = "complete.obs")

correlacion_df <- data.frame(Variable1 = "copiesSold", 
                             Variable2 = "revenue", 
                             Correlacion = round(correlacion, 2))
correlacion_df %>%
  kable(caption = "Correlación entre las copias vendidas y la recaudación") %>%
  kable_styling(full_width = F)
```


El resultado de la correlación es de 0.63, lo que indica una relación positiva significativa, aunque no muy fuerte. 

Por último, se realizará un modelo de regresión lineal para analizar cómo varía la recaudación en función de las copias vendidas. Para ello, se han eliminado varios puntos atípicos con valores muy altos tanto en las Copias Vendidas como en la Recaudación.

```{r}

umbral_copiesSold <- 10e6
umbral_revenue <- 200e6

lab_filt <- lab %>%
  filter(copiesSold <= umbral_copiesSold & revenue <= umbral_revenue)

modelo <- lm(revenue ~ copiesSold, data = lab_filt)

summary(modelo)

ggplot(lab_filt, aes(x = copiesSold, y = revenue)) +
  geom_point(size = 2, alpha = 0.7) +  
  geom_smooth(method = "lm", color = "blue") +
  scale_x_continuous(labels = function(x) {
    ifelse(x >= 1e6, 
           paste0(format(x / 1e6, big.mark = ",", digits = 2), " M"),
           ifelse(x >= 1e3, 
                  paste0(format(x / 1e3, big.mark = ",", digits = 2), " K"), 
                  format(x)))
  }) +
  scale_y_continuous(labels = function(x) {
    ifelse(x >= 1e6, 
           paste0(format(x / 1e6, big.mark = ",", digits = 2), " M"),
           ifelse(x >= 1e3, 
                  paste0(format(x / 1e3, big.mark = ",", digits = 2), " K"), 
                  format(x)))
  }) +
  labs(title = "Regresión Lineal: Copias Vendidas vs Recaudación",
       x = "Copias Vendidas",
       y = "Recaudación (en miles de dólares)") +
  theme_minimal()
```


Como se puede observar, las variables copiesSold y revenue muestran una relación más fuerte cuando el número de copias vendidas es inferior a 2,5 millones. Esto sugiere que, aunque la recaudación depende en gran medida de las copias vendidas,pero no de forma exclusiva, ya que, dicha relación tiende a debilitarse a medida que el número de copias vendidas aumenta.

### Estudio de las variables PRICE Y REVENUE

En primer lugar, con el objetivo de comprender cómo varían los beneficios en cuanto al precio de los juegos de nuestra muestra y distinguir si hay una correlación entre dichas características, vamos a realizar una tabla de contingencia para ambas variables, donde podremos observar la frecuencia absoluta y los porcentajes (frec. relativa) de una variable frente a la otra y descartar posibles outliers.

```{r}

  price_filtrado_breaks <- seq(min(lab_filtrado$price), max(lab_filtrado$price), length.out = 8)
  lab_filtrado$price_intervalos <- cut(lab_filtrado$price, breaks = price_filtrado_breaks, include.lowest = TRUE)  
  
  revenue_breaks <- c(20000, 5000000, 50000000, 85000000, 150000000, 250000000, 335000000, 500000000, 585000000, 650000000, 755000000, 850000000)
  revenue_labels <- c("[20k-5M]", "(5M-50M]", "(50M-85M]", "[85M-150M]", "(150M-250M]", "(250M-335M]", "(335M-500M]", "(500M-585M]", "(585M-650M]", "(650M-755M]", "(755M-850M]")
  lab_filtrado$revenue_intervalos <- cut(lab_filtrado$revenue, breaks = revenue_breaks, labels = revenue_labels, include.lowest = TRUE)
  
  tabla_abs_priceRevenue <- table(lab_filtrado$revenue_intervalos, lab_filtrado$price_intervalos)

  tabla_rel_priceRevenue <- prop.table(tabla_abs_priceRevenue) * 100
  
  tabla_contingencia_priceRevenue <- matrix(paste(tabla_abs_priceRevenue, "(", round(tabla_rel_priceRevenue, 2), "%)", sep = ""),
                            nrow = nrow(tabla_abs_priceRevenue), ncol = ncol(tabla_abs_priceRevenue))

  rownames(tabla_contingencia_priceRevenue) <- rownames(tabla_abs_priceRevenue)
  colnames(tabla_contingencia_priceRevenue) <- colnames(tabla_abs_priceRevenue)

  kable(tabla_contingencia_priceRevenue, caption = htmltools::tags$div(style = "text-align: center;", 
                                     htmltools::tags$h4(htmltools::tags$strong("y: beneficios(dólares) // x: precio(dólares)")))) |>
  kable_styling(latex_options = c("striped", "hold_position"))
```
Como podemos apreciar, nuestros datos se acumulan en el primer intervalo y en el resto de intervalos no tienen un peso significativo a considerar en este análisis, por lo que vamos a realizar un filtrado de la variable hasta los 5M $ de beneficio para quedarnos únicamente con el primer intervalo, eliminando un total de 69 muestras del dataset.

```{r}
  lab_filtrado2 <- lab_filtrado[lab_filtrado$revenue <= 5000000,]


  revenue_filtrado2 <- lab_filtrado2$revenue_intervalos
  
  revenue_breaks2 <- c(20000, 50000, 100000, 250000 ,500000, 1000000, 5000000)

  revenue_labels2 <- c("[20k-50k]", "(50k-100k]", "(100k-250k]", "(250k-500k]", "(500k-1M]", "(1M-5M]")
  
  lab_filtrado2$revenue_intervalos <- cut(lab_filtrado2$revenue, breaks = revenue_breaks2, labels = revenue_labels2, include.lowest = TRUE)
  
  tabla_abs_priceRevenue2 <- table(lab_filtrado2$revenue_intervalos, lab_filtrado2$price_intervalos)

  tabla_rel_priceRevenue2 <- prop.table(tabla_abs_priceRevenue2) * 100
  
  tabla_contingencia_priceRevenue2 <- matrix(paste(tabla_abs_priceRevenue2, "(", round(tabla_rel_priceRevenue2, 2), "%)", sep = ""),
                            nrow = nrow(tabla_abs_priceRevenue2), ncol = ncol(tabla_abs_priceRevenue2))

  rownames(tabla_contingencia_priceRevenue2) <- rownames(tabla_abs_priceRevenue2)
  colnames(tabla_contingencia_priceRevenue2) <- colnames(tabla_abs_priceRevenue2)

  kable(tabla_contingencia_priceRevenue2, caption = htmltools::tags$div(style = "text-align: center;", 
                                     htmltools::tags$h4(htmltools::tags$strong("y: beneficios(dólares) // x: precio(dólares)")))) |>
  kable_styling(latex_options = c("striped", "hold_position"))
  
```

Ante los datos de esta tabla, podemos obtener una primera conclusión, no existe una fuerte relación (aparentemente) entre los beneficios obtenidos y el precio impuesto para el juego. Sin embargo podemos apreciar una concentración de frecuencias entre los primeros intervalos de ambas variables, lo que indica que a priori, puede haber una correlación (ciertamente no muy elevada) entre la obtención de menores beneficios e imponer un precio bajo (entre 0$ y 20$).

Curiosamente, ni imponer un precio más elevado asegura mayores beneficios, ni imponer un precio más bajo (incluso 0$) implica obtener beneficios menores.


A continuación, realizaremos dos gráficas de dispersión, la primera estará basada en el ajuste de regresión más adecuado posible (mediante la función geom_smooth) con el dataset total y la segunda, continuando así el estudio de correlación, consistirá en un ajuste de regresión lineal con el dataset filtrado a 5M $ de beneficios.

```{r}
  lab_filtrado |>
  
  ggplot(aes(x = revenue, y = price)) +
  geom_point() +
  geom_smooth() +
  labs(title = "Gráfico de dispersión con ajuste de regresión automático:") +
  scale_x_continuous(breaks = c(0, 200000000, 400000000, 600000000, 800000000), labels = c("0", "200M", "400M", "600M", "800M")) +
  theme_bw()
```

```{r}
  lab_filtrado2 |> 
  
  ggplot(aes(x = revenue, y = price)) +
  geom_point() +
  geom_smooth(method = lm, se = FALSE) +
  labs(title = "Gráfico de dispersión con ajuste de regresión lineal:")+
  scale_x_continuous(breaks = c(0, 1000000, 2000000, 3000000, 4000000, 5000000), labels = c("0", "1M", "2M", "3M", "4M", "5M"))+
  theme_bw()
```

Cabe destacar, que en la primera gráfica, la mayoría de datos se concentran en una zona y la dispersión de puntos es tan elevada para los beneficios altos que la interpretación de la recta se vuelve prácticamente imposible, mientras que en la segunda gráfica podemos denotar un aumento positivo y progresivo de los beneficios en cuanto el precio aumenta.

Para mayor comprensión de ambos gráficos, mostramos el siguiente resumen numérico:

```{r}
  summary(lab_filtrado2 |> select(revenue, price) |> with(lm(revenue ~ price)))
```

Aproximadamente, a través de los valores del resumen (Estimate Std. (revenue) = 131002 // Estimate Std. (price) = 16368) la recta de nuestro modelo ajustado es la siguiente:

`revenue = 16368 × price + 131002`

Lo que nos indica una función lineal creciente, donde los beneficios aumentan a medida que los precios aumentan. Además dicha función nos indica el valor esperado de beneficios cuando el precio es 0$ (valor totalmente válido en este estudio) que sería de 131002$.

```{r}
  cor(lab_filtrado2$price, lab_filtrado2$revenue)
```
En cuanto a la correlación de una variable con otra y predictibilidad del modelo creado, el valor del coeficiente de correlación lineal (0.25) nos sugiere una relación lineal positiva débil entre price y revenue y el valor R-squared (0.0619) indica que el 6.19% de la variabilidad de los beneficios es explicada por el precio, lo cual es un porcentaje extremadamente bajo. 

Esto sugiere que, el precio no afecta directamente a los beneficios y, que hay otros factores que también influyen en los beneficios que deberemos tener en cuenta en nuestro modelo. Además, se trata de un modelo poco preciso, ya que el valor del Residual standard error (721900) nos indica que la varianza residual es de 849.65, cuyo valor es muy elevado.

A continuación se muestra la matriz de varianzas y covarianzas del modelo:

```{r}
  summary(lab_filtrado2 |> select(revenue, price) |> with(lm(revenue ~ price))) |>
  vcov()
```
Dicha matriz nos indica una varianza muy elevada tanto como para revenue (1149614621) como para price (2843591) y una covarianza de -47250453, lo que reafirma nuestra teoría de que no hay una relación fuerte ni concisa entre ambas variables.


### Estudio de las variables AVGPLAYTIME Y REVENUE

Lo primero de todo, para saber si hay una relación fuerte entre el tiempo de juego de las personas (avgPlaytime)y la recaudación (revenue), vamos a utilizar una tabla de correlación.

```{r}

correlacion <- cor(lab$avgPlaytime, lab$revenue, use = "complete.obs")

correlacion_df <- data.frame(Variable1 = "avgPlaytime", 
                             Variable2 = "revenue", 
                             Correlacion = round(correlacion, 2))

correlacion_df %>%
  kable(caption = "Correlación entre el tiempo de juego medio y la recaudación") %>%
  kable_styling(full_width = F)

```


La tabla nos indica que la correlación entre ambas variables es de 0.08, es decir, una cifra cercana a 0. Esto nos dice que la relación entre ambas variables es muy débil o inexistente.

Los juegos con menos horas de juego pueden tener precios altos y al contrario, los juegos muy largos pueden atraer a jugadores que invierten más tiempo, pero sin tener que gastar más dinero.

A continuación, vamos a visualizar un gráfico de dispersión para poder ver la relación entre las variables de forma más clara y directa.Los puntos en el gráfico representan diferentes juegos, donde el eje "x" indica el tiempo promedio de juego, y el eje "y" representa la recaudación total obtenida por esos juegos.

Para obtener una mejor comprensión visual, se ha utilizado una escala logarítmica en el eje de recaudación debido a la amplia variación en las cifras de ingresos, que van desde valores muy bajos hasta cientos de millones. Esto nos permite que los datos sean más visibles y comparables.


```{r}
lab |> 
  ggplot(aes(x = avgPlaytime, y = revenue)) +
  
  geom_point(alpha = 0.7, color = "blue") +
  
  scale_y_log10() +
  
  xlim(0, 300) +

  labs(
    x = "Tiempo promedio de juego (horas)",
    y = "Recaudación (log scale)",
    title = "Relación entre Tiempo de Juego y Recaudación en Steam"
  ) +

  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 14),
    axis.title.x = element_text(face = "bold"),
    axis.title.y = element_text(face = "bold")
  )

```

El gráfico muestra una concentración de juegos con un tiempo promedio bajo (cercano a 0 horas), y una gran dispersión en los valores de recaudación. Sin embargo, a pesar de que algunos juegos tienen tiempos de juego elevados (cercanos a las 300 horas), estos no necesariamente generan más ingresos que otros con menos tiempo jugado.

Los puntos se distribuyen en su mayoría en la esquina inferior izquierda (poco tiempo jugado y baja recaudación), pero no hay un patrón claro de que a mayor tiempo jugado haya una mayor recaudación. El hecho de que los puntos estén tan juntos en la parte baja también sugiere que la mayoría de los juegos tienen tiempos de juego relativamente cortos.


A modo de conclusión podemos decir que el tiempo de juego influye de forma mínima en la recaudación.


### Estudio de las variables REVIEWSCORE Y REVENUE
A continuación vamos a analizar  si la puntuación asociada al videojuego afecta realmente a la recaudación. Para ello vamos a utilizar una gráfica de dispersión mediante la cual se verá la cantidad de videojuegos beneficiados por su puntuación.

```{r}

ggplot(data = labNo0, aes(x = reviewScore, y = revenue)) +

  geom_point(alpha = 0.5) +  

  labs(title = "Relación entre Puntuación y Recaudación",

       x = "Puntuación",
       y = "Recaudación") +

  theme_minimal()  # Usar un tema minimalista

```

Podemos apreciar cómo la mayoría de puntos se agrupan en la parte baja de la gráfica indicando que pese a  la puntuación alta que puedan tener, son pocos los que tienen recaudaciones altas. Lo que sí queda claro es que de los juegos con poca puntuación, ninguno sobresale. De todas formas comprobemos mediante un análisis de regresión para obtener un modelo cuantitativo.

```{r}

modelo <- lm(revenue ~ reviewScore, data = labNo0) 

summary(modelo)  

ggplot(data = labNo0, aes(x = reviewScore, y = revenue)) +

  geom_point(alpha = 0.5) +  

  geom_smooth(method = "lm", color = "blue") +  

  labs(title = "Relación entre Puntuación y Recaudación con Línea de Regresión",

       x = "Puntuación",
       y = "Recaudación") +

  theme_minimal()

```

Ahora podemos ver cómo la línea de regresión no cambia, se mantiene prácticamente horizontal. Esto deja claro que la recaudación que se obtiene no tiene mucho que ver con la puntuación  que tenga el videojuego, son escasos los que por tener una alta puntuación tienen tambien una alta recaudación.


### Estudio de las variables PUBLISHERCLASS Y REVENUE
En este apartado, queremos comprobar si el tipo de empresa afecta a la recaudación. Para ello, vamos a utilizar una gráfica box-plot y un gráfico de barras para que sea más visual.

```{r}

ggplot(lab, aes(x = publisherClass, y = revenue)) +
  geom_bar(stat = "summary", fun = "mean", fill = "steelblue") +  # Barras que muestran la media
  labs(title = "Recaudación por tipo de empresa",
       x = "Tipo de empresa",
       y = "Recaudación promedio") 

```

Como se puede observar, los juegos que menos recaudan, son los de empresa tipo "Indie", a pesar de que estos son la mayoría de los juegos que salen. A continuación, realizaremos una gráfica box-plot para analizar mejor los datos. Por otra parte, esta el tipo "Hobbyist", que no tiene sentido analizar debido a que es una única prueba, y el objetivo de ese tipo de empresa no es la recaudación de dinero.

```{r}

ggplot(lab, aes(x = publisherClass, y = revenue)) +
  geom_boxplot(fill = "lightblue", color = "darkblue") +
  labs(title = "Distribución de la Recaudación por Tipo de Empresa",
       x = "Tipo de Empresa",
       y = "Recaudación") +
  theme_minimal()

```

Debido a la disparidad entre las muestras que tenemos, necesitaremos aplicar una escala logarítmica para evitar la asimetría en dichas muestras ya que la distribuición es muy sesgada.

```{r}

ggplot(lab, aes(x = publisherClass, y = revenue)) +
  geom_boxplot(fill = "lightblue", color = "darkblue") +
  scale_y_log10() +  
  labs(title = "Distribución de la Recaudación por Tipo de Empresa (Escala Logarítmica)",
       x = "Tipo de Empresa",
       y = "Recaudación (log)") +
  theme_minimal()

```

Aquí podemos observar como sí hay juegos "Indie" con una recaudación superior a la media del resto de empresas, pero son casos aislados y la mayor parte de los "Indies", generan mucho menos que los juegos "AAA" y "AA". 


# Conclusiones 

Para las conclusiones de nuestro estudio, responderemos a las preguntas propuestas al principio del estudio.

`- ¿Los indies recaudan más dinero que los AA o AAA?`

Aquí podemos concluir que no, de hecho, aunque sean la mayoría de videojuegos, los que más recaudan con diferencia son los AAA y los AA, a pesar de algunos casos aislados dentro de la categoría Indie.

`- ¿Los juegos que venden más copias recaudan más dinero?`

Podríamos afirmar que sí, ya que en la regresión lineal, se puede observar como es positiva, además se pueden observar otros factores como la correlación que tienen estas dos variables que es significativa.

`- ¿Los juegos más caros recaudan más dinero que los baratos?`

En cuanto a estas dos variables, a pesar de que la regresión lineal es positiva, no es demasiado notable, además, la correlación de ambas variables es débil. Por lo que podemos concluir que no afecta apenas el que un juego sea más caro que otro. De hecho, esta relación se puede además relacionar con el análisis del tipo de empresa, ya que los juegos que más recaudan (los AAA), suelen tener un precio bastante elevado.

`- ¿Los juegos más largos recaudan más dinero que los que son más cortos?`

En esta relación, podemos afirmar que no tienen apenas relación como hemos podido observar en el análisis de correlaciones. Como conclusión, que un juego sea más largo o más corto, no influye prácticamente en nada a la recaudación del mismo.

`- ¿Los juegos con buenas valoraciones recaudan más que los que tienen peor puntuación?`

Por último, estas dos variables, tenían una correlación muy baja, de hecho, la más baja del estudio. Es decir, podríamos haber concluido desde el principio que no tenían relación ninguna. Aún así podemos ver como en el ajuste de regresión lineal, la recta es prácticamente horizontal. Por ello, podemos concluir que las valoraciones no tienen nada que ver con lo que un juego pueda recaudar. Como dijimos en el análisis detallado de estas dos variables, puede deberse a que estas valoraciones son de los usuarios y no de profesionales como podría ser en "Metacritic".


## LINK AL REPOSITORIO DE GITHUB

1. **Repositorio de GitHub**: https://github.com/danitjela/PracticaEstadistica
