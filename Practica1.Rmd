---
title: 'Práctica Estadística Descriptiva- GRUPO 9'
author: "RAÚL BENÍTEZ TIBURÓN, ESTER DÍAZ MONZONIS, AROA QUIROGA MARTÍNEZ, SANDRA SÁEZ PIÑA, DANIELA TOCINO JIMÉNEZ"
date: "Estadística - Curso 2024/2025"

output: 
  bookdown::html_document2:
    toc: yes
    toc_float: yes
  # bookdown::pdf_document2:
  #   includes:
  #     in_header: preamble.tex
---

```{r setup, include=FALSE, purl=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      eval = TRUE, 
                      warning = FALSE,
                      message = FALSE,
                      error = TRUE)
``` 

# Introducción y definición de objetivos

El archivo Steam_2024_bestRevenue_1500.csv contiene una recopilación de datos de los 1500 juegos mejor valorados lanzados en Steam desde el 1 de enero de 2024, hasta el 9 de septiembre de 2024.Con el analisis de dicho archivo pretendemos estudiar la relación entre...

Además del objetivo mencionado, también queremos dar respuesta a las siguientes preguntas: 

- Los indies generan más dinero que los AA o AAA?
- El precio influye en la cantidad de copias vendidas?
- Es mayor el precio de los indies o de los AA o AAA?
- Hay mas jugadores en juegos indies o en AA o AAA?
- Tienen mejores criticas los indies o los AAA, AA?
- Depende el precio de las críticas? Es mejor juego un indie o un AA o AAA?
- Depende la fecha de salida con el numero de copias vendidas?
- Son más largos los indies o los AA o AAA, y hacen que el precio sea mayor?

De todas las variables que aparecen, la de "steamId" no la vamos a analizar porque no es necesaria para conseguir nuestro objetivo dentro del proyecto.También cabe mencionar que, el estudio de la variable "reviewScore" nos ha llamado la atención al observar que gran cantidad de los juegos tienen de valoración un 0, lo cual puede significar que, a la hora de cargar los datos en la página del dataset, ha podido haber algún error.


# Importación de datos y carga de paquetes

Para comenzar nuestro análisis descriptivo, necesitamos cargar una serie de paquetes en R que facilitarán la manipulación de datos, la creación de gráficos, y la presentación de tablas. Estos paquetes incluyen 'tidyverse' para la manipulación de datos, 'summarytools' y 'corrplot' para análisis estadísticos, 'GGally' para gráficos de pares, 'gt' y 'flextable' para tablas avanzadas, 'knitr' para la integración de R con documentos de texto, 'dplyr' para la modificación de los datos en un data frame.

```{r}

library(tidyverse)
library(summarytools)
library(GGally)
library(gt)
library(flextable)
library(knitr) 
library(corrplot)
library(dplyr)
library (kableExtra)

```

A continuación, leeremos y almacenaremos los datos de nuestro estudio. Para ello, utilizamos el método read.csv(), al cual le introducimos como parámetros: la ruta relativa del archivo, se especifica que el archivo tiene una fila de encabezados para los nombres de las variables y el tipo de separación de los elementos en el archivo (en nuestro caso commas). El resultado de esta operación se almacena en la variable lab con la que trabajaremos durante el análisis.

```{r}

  lab <- read.csv("DATA/Steam_2024_bestRevenue_1500.csv", header = TRUE, sep = ",")
  # 'mutate(fecha = as.Date(fecha))' transforma la columna 'fecha' a formato de fecha.
  # 'mutate()' es una función del paquete dplyr que se utiliza para añadir nuevas variables o transformar las existentes.
  # 'as.Date()' convierte los datos a formato de fecha.
  lab |>
  mutate(releaseDate = as.Date(releaseDate))
  
```


# Diccionario de datos

En esta sección, presentamos un diccionario de datos que detalla cada variable contenida en nuestro conjunto de datos 'Steam_2024_bestRevenue_1500.csv'. Las variables abarcan desde el nombre de cada uno de los juegos, hasta los desarrolladores de cada uno de ellos.

* `name`: nombre.
    - Variable tipo: Identificador. 
    
* `releaseDate``: fecha de salida.
    - Variable tipo: Marca de tiempo.
    
* `copiesSold`: copias vendidas.
    - Variable tipo: Cuantitativa / Discreta. 
    
* `price`: precio.
    - Variable tipo: Numérica / Continua. 
    
* `revenue``: recaudación.
    - Variable tipo: Cuantitativa / Discreta.
    
* `avgPlaytime`: tiempo medio de juego.
    - Variable tipo: Cuantitativa / Continua.
    
* `reviewScore`: valoración.  
    - Variable tipo: Cuantitativa / Discreta.
    
* `publisherClass`: categoría de la empresa.
    - Variable tipo: Cualitativa / Multinivel.
    
* `publishers`: editores.
    - Variable tipo: Identificador.
    
* `developers`: desarrolladores.
    - Variable tipo: Identificador.
    
* `steamId`: Id de steam
    - Variable tipo: Identificador.



# Muestra del dataset

Ahora, vamos a echar un vistazo a las primeras filas de nuestro dataset para obtener una comprensión inicial de los datos con los que estamos trabajando. Este paso es crucial para familiarizarnos con el tipo de datos y para verificar que la importación se haya realizado correctamente. Utilizaremos funciones del paquete 'dplyr' para seleccionar las primeras 10 filas del dataframe 'lab', y luego el paquete 'gt' para presentar estos datos de una manera clara y estructurada.

```{r}
# 'lab |> slice_head(n=10)' selecciona las primeras 10 filas del dataframe 'lab'.
# 'lab' es el dataframe que se ha leído y preparado en los pasos anteriores.
# '|>' es el operador de tubería en R que permite pasar el resultado de una función a la siguiente.
lab |>  
  # 'slice_head(n=10)' es una función del paquete dplyr que selecciona las primeras 'n' filas del dataframe.
  # En este caso, selecciona las primeras 10 filas.
  slice_head(n=10) |> 

  # 'gt()' es una función del paquete gt que crea una tabla elegante y bien formateada.
  # Convierte el resultado del dataframe reducido a una tabla que puede ser más fácilmente formateada y presentada.
  gt()

```


# Análisis exploratorio de datos

Iniciaremos nuestro análisis exploratorio de datos (EDA) para obtener una comprensión profunda del conjunto de datos del laboratorio. Este proceso nos permitirá descubrir patrones, detectar anomalías, probar hipótesis y verificar supuestos a través de diversos métodos estadísticos y gráficos.

## Datos univariantes

Comenzaremos nuestro análisis exploratorio de datos con un enfoque en los datos univariantes. Este enfoque nos permite entender la distribución y frecuencia de cada variable individualmente.

### Estudio de la variable COPIESSOLD

Iniciamos nuestro EDA con un enfoque en los datos univariantes, creando tablas de frecuencias para obtener una visión general de la distribución de nuestras variables categóricas.

Primero, generamos un histograma agrupando la variable 'copiesSold' por intervalos, esto nos ayuda a entender cuántas copias han sido vendidas de cada juego en toda nuestra muestra, si hay concentraciones de valores o si hay posibles outliers. Debido a que sus valores van desde 500 a 30.000.000 (ventas), asumimos que la distribución de dicha variable es dispersa y para solventarlo usaremos una escala logarítimica. 

```{r}

  lab$logCopiesSold <- log10(lab$copiesSold)

  # Definir los intervalos logarítmicos
  # Elige un rango adecuado en la escala logarítmica para crear los intervalos.
  lab$copiesSold_intervalos_log <- cut(lab$logCopiesSold, breaks = seq(floor(min(lab$logCopiesSold)), 
                                       ceiling(max(lab$logCopiesSold)), by = 0.5), include.lowest = TRUE, right = FALSE)
  
  # Crear etiquetas para los intervalos con el formato logarítmico y su equivalente en la escala original
  # Usamos 'paste0' para crear etiquetas que incluyan ambas escalas.
  lab$copiesSold_intervalos_etiquetas <- sapply(levels(lab$copiesSold_intervalos_log), function(x) {
    rango_log <- as.numeric(gsub("[^0-9.-]", "", unlist(strsplit(x, ","))))
    paste0("log10([", round(10^rango_log[1], 0), ", ", round(10^rango_log[2], 0), ")) = ", x ,"")
  })

  # Reemplazar los niveles de 'copiesSold_intervalos_log' por las nuevas etiquetas
  levels(lab$copiesSold_intervalos_log) <- lab$copiesSold_intervalos_etiquetas

  # Calcula la tabla de frecuencias de la variable 'copiesSold' en el dataframe 'lab'.
  copiesSold_tablaFrequencias <- table(lab$copiesSold_intervalos_log) |> 
  
  # Convierte la tabla de frecuencias en un dataframe.
  as.data.frame() |> 
  
  # Añade una nueva columna 'F' calculando la frecuencia relativa acumulada.
  # Esto se logra sumando las frecuencias (Freq) acumulativamente y dividiéndolas por el número total de filas en 'lab'.
  mutate(freqRelativa = Freq / sum(Freq), freqAbsAcumulada = cumsum(Freq), freqRelAcumulada = cumsum(freqRelativa)) |>
  
  # Ordena la tabla
  arrange(desc(Freq)) |>
  
  # Convierte el dataframe resultante en una tabla 'gt' para formateo y estilización avanzados.
  gt() |> 
  
  # Añade un título en cursiva y negrita a la tabla de frecuencias
  tab_header(
    title = md("**_Nº de copias vendidas_**")
  ) |>
  
  # Cambia las etiquetas de las columnas a notación matemática.
  cols_label(Var1 = "\\(x_i\\)", Freq = "\\(n_i\\)", freqRelativa = "\\(f_i\\)", 
  freqAbsAcumulada = "\\(N_i\\)", freqRelAcumulada = "\\(F_i\\)") |>  
  
  # Formatea los números a mostrar cuatro decimales.
  fmt_number(3, decimals = 4) |> 
  
  # Aplica un estilo de texto en negrita a la fila de encabezado de la tabla.
  tab_style(style = list (cell_text(weight = "bold")), locations = cells_column_labels()) |>
  
  print(copiesSold_tablaFrequencias)

```
### Estudio de la variable PRICE

A continuación, creamos una tabla de frecuencias para 'price', proporcionando una visión clara de cuánto cuesta una copia de cada juego. Esta tabla también incluye la frecuencia relativa acumulada para cada categoría.

```{r}

 # Calcula la tabla de frecuencias de la variable 'copiesSold' en el dataframe 'lab'.
  table(lab$price) |> 
  
  # Convierte la tabla de frecuencias en un dataframe.
  as.data.frame() |> 
  
  # Añade una nueva columna 'F' calculando la frecuencia relativa acumulada.
  # Esto se logra sumando las frecuencias (Freq) acumulativamente y dividiéndolas por el número total de filas en 'lab'.
  mutate(freqRelativa = Freq / sum(Freq), freqAbsAcumulada = cumsum(Freq), freqRelAcumulada = cumsum(freqRelativa)) |>
  
  
  # Ordena la tabla
  arrange(desc(Freq)) |>
  
  # Convierte el dataframe resultante en una tabla 'gt' para formateo y estilización avanzados.
  gt() |> 
  
  # Añade un título en cursiva y negrita a la tabla de frecuencias
  tab_header(
    title = md("**_Precio por copia ($)_**")
  ) |>
  
  # Cambia las etiquetas de las columnas a notación matemática.
  cols_label(Var1 = "\\(x_i\\)", Freq = "\\(n_i\\)", freqRelativa = "\\(f_i\\)", 
  freqAbsAcumulada = "\\(N_i\\)", freqRelAcumulada = "\\(F_i\\)") |>  
  
  # Formatea los números a mostrar cuatro decimales.
  fmt_number(3, decimals = 4) |> 
  
  # Aplica un estilo de texto en negrita a la fila de encabezado de la tabla.
  tab_style(style = list (cell_text(weight = "bold")), locations = cells_column_labels())

```

A continuación, creamos otro histograma para 'price', esta vez utilizando un enfoque más tradicional con la función `hist()` de R, proporcionando un estilo diferente y más opciones de personalización.

```{r}

  ggplot(data.frame(x = lab$price), aes(x = x)) +
  geom_histogram(binwidth = 5, fill = "skyblue", color = "black", 
                 aes(y = ..density..), alpha = 0.6) +
  stat_function(fun = dnorm, args = list(mean = mean(lab$price), 
                sd = sd(lab$price)), color = "red", size = 1.5) +
  theme_bw() +
  labs(title = "Distribución del precio por copia ($)",
       x = "Precio por copia",
       y = "Frecuencia absoluta") 

```

```{r}

  ggplot(data.frame(x = lab$price), aes(x = x)) +
  geom_histogram(binwidth = 5, fill = "skyblue", color = "black", 
                 aes(y = ..count../sum(..count..), alpha = 0.6)) +
  stat_function(fun = dnorm, args = list(mean = mean(lab$price), 
                sd = sd(lab$price)), color = "red", size = 1.5) +
  theme_bw() +
  labs(title = "Distribución del precio por copia ($)",
       x = "Precio por copia",
       y = "Frecuencia relativa") 

```

```{r}
  lab|> select(price) |> descr() |> kable(digits = 2)
```



### Gráficos de barras

Ahora, visualizamos la distribución de las categorías mediante gráficos de barras. Estos gráficos son una herramienta efectiva para representar visualmente la frecuencia de cada categoría en nuestras variables categóricas.

Este gráfico de barras muestra la frecuencia absoluta de cada copia vendida en nuestro dataset. Es una forma sencilla y directa de visualizar la cantidad total de copias vendidas.

```{r}
# Inicia una visualización de ggplot con 'lab' como el dataframe y 'copiesSold' como variable en el eje x.
lab |> 
  ggplot(aes(x = copiesSold)) +
  # Añade un gráfico de barras, rellenando las barras con el color #CB0017.
  geom_bar(fill = "#2596be") +
  # Aplica un tema predeterminado en blanco y negro para la visualización.
  theme_bw() + 
  # Establece los títulos del gráfico, eje x, y eje y.
  labs(title = "Nº de copias vendidas", 
       x = "Tipo",
       y = "Frecuencia absoluta")
```

Aquí, empleamos un enfoque ligeramente diferente al invertir el orden de las barras para la variable 'imperfecciones', lo que nos permite examinar la distribución desde otra perspectiva.

```{r}
# 'fct_rev' invierte el orden de los factores para que el gráfico se muestre en orden inverso.
# 'as_factor' convierte la columna 'imperfecciones' en un factor si no lo es ya.
lab |> 
  mutate(imperfecciones = fct_rev(as_factor(copiesSold))) |> 
  # Inicio de la creación del gráfico con ggplot2, especificando los datos y mapeando
  # la variable 'imperfecciones' en el eje y.
  ggplot(aes(y = copiesSold)) +
  # 'geom_bar' añade barras al gráfico. 'fill' especifica el color de relleno de las barras.
  geom_bar(fill = "#2596be") +
  # Aplica un tema blanco y negro al gráfico para un diseño más limpio y profesional.
  theme_bw() +
  # Personaliza las etiquetas de los ejes y el título del gráfico. 'expression' permite
  # usar expresiones matemáticas en las etiquetas.
  labs(x = expression("Frecuencia absoluta ("*n[i]*")"),
       y = "Número de imperfecciones")
```

En este gráfico, exploramos la proporción relativa de los tipos de quesos en nuestro conjunto de datos, utilizando un gráfico de barras que muestra las proporciones en forma de porcentajes. Además, se incluye un gradiente de color en las barras para mostrar las frecuencias absolutas.

```{r}
# Inicia una visualización de ggplot con 'lab' como el dataframe, 'tipo' como variable en el eje x,
# y calcula la proporción (after_stat(prop)) para el eje y. Agrupación establecida para cálculos de proporción.
ggplot(lab, aes(x = tipo, y =  after_stat(prop), group = 1)) +
  # Añade un gráfico de barras con conteo como estadística y rellena las barras basado en el conteo de 'tipo'.
  geom_bar(aes(fill = after_stat(count)), stat = "count") +
  # Escala el eje y para mostrar las etiquetas como porcentajes.
  scale_y_continuous(labels = scales::percent) +  # Convierte las etiquetas de y en porcentajes
  # Aplica un tema predeterminado en blanco y negro para la visualización.
  theme_bw() + 
  # Establece los títulos del gráfico, eje x, y eje y.
  labs(title = "Tipos de queso", 
       x = "Tipo",
       y = "Frecuencia relativa") +
  # Añade un degradado de color a las barras basado en la frecuencia de conteo, desde 'skyblue' a '#CB0017'.
  scale_fill_gradient("Frecuencia", low = "skyblue", high = "#CB0017")  # Opcional: color de relleno basado en la frecuencia

```

Este gráfico muestra la proporción de análisis realizados por cada analista. Utilizamos un enfoque diferente al ordenar los analistas por su proporción y representar tanto la proporción relativa como el conteo absoluto en el gráfico.

```{r}
# Primero, calcula las proporciones y conserva el conteo original
# 'lab' es el dataframe que contiene los datos.
# 'count(copiesSold)' cuenta cuántas veces aparece cada 'copiesSold'.
# 'mutate(prop = n / sum(n))' añade una nueva columna 'prop' que representa la proporción relativa.
copiesSold_prop <- lab %>%
  count(copiesSold) %>%
  mutate(prop = n / sum(n))

# Luego, usa ggplot para visualizar
# 'ggplot()' inicia la construcción de un gráfico.
# 'aes(x = reorder(copiesSold, prop), y = prop, fill = n)' define las estéticas:
# 'x = reorder(copiesSold, prop)' ordena los copiesSold en el eje x según su proporción.
# 'y = prop' asigna la proporción relativa al eje y.
# 'fill = n' usa el conteo original para el color de las barras.
ggplot(copiesSold_prop, aes(x = reorder(copiesSold, prop), y = prop, fill = n)) +
  
  # 'geom_bar(stat = "identity")' crea un gráfico de barras. 
  # 'stat = "identity"' indica que ya se proporcionaron las alturas de las barras (proporciones).
  geom_bar(stat = "identity") +
  
  # 'scale_y_continuous(labels = scales::percent)' configura el eje y para mostrar las etiquetas como porcentajes.
  scale_y_continuous(labels = scales::percent) +

  # 'theme_bw()' aplica un tema visual en blanco y negro al gráfico.
  theme_bw() +

  # 'labs()' establece los títulos y etiquetas del gráfico.
  # 'title', 'x', 'y' definen el título del gráfico y los títulos de los ejes x e y respectivamente.
  labs(title = "Nº de copias vendidas", x = "Tipo", y = "Frecuencia relativa") +

  # 'scale_fill_gradient()' define un degradado de color para las barras.
  # 'low' y 'high' especifican los colores para los valores bajos y altos del conteo respectivamente.
  scale_fill_gradient("Frecuencia", low = "skyblue", high = "#CB0017")


```


### Estudio de la variable AVGPLAYTIME

A continuación, nos enfocamos en el tiempo que dedican las personas a cada uno de los juegos.
Una herramienta crucial para entender la distribución de nuestra variable cuantitativa es el histograma, ya que este gráfico nos permitirá observar la forma y la dispersión de los datos.

Vamos a utilizar el color 'steelblue' para las barras, lo que nos permite observar la distribución de la variable de manera sencilla.

```{r}
# 'lab |> ggplot(aes(avgPlaytime)) +' inicia la construcción de un gráfico utilizando ggplot2 con datos del dataframe 'lab'.
lab |> ggplot(aes(avgPlaytime)) +
  # 'aes(avgPlaytime)' establece la estética del gráfico, asignando la variable 'avgPlaytime' del dataframe 'lab' al eje x.
  
  # 'geom_histogram()' añade un histograma al gráfico. Un histograma es útil para visualizar la distribución de una variable continua.
  geom_histogram(
    
    fill = "steelblue",  # 'fill = "steelblue"' establece el color de relleno de las barras del histograma a azul acero.
             
    col = "white",      # 'col = "white"' define el color del borde de las barras del histograma como blanco.
    breaks = seq(0,100, by = 10)
  ) +
  
  # 'theme_bw()' aplica un tema en blanco y negro al gráfico.
  # Este tema proporciona un contraste visual claro y es popular por su simplicidad y legibilidad.
  theme_bw() +
    labs(x = "Tiempo promedio de juego (horas)", y = "Frecuencia", title = "Distribución de tiempo de juego por   intervalos")

```
Si analizamos el histograma se puede observar que la mayoría de los jugadores dedican menos de 10 horas a los videojuegos. Hay una caída significativa en la frecuencia de jugadores que juegan más de 10 horas, lo que sugiere que pocos jugadores le dedican tanto tiempo al juego. Esto puede indicar que muchos juegos no requieren un compromiso prolongado, o que los jugadores tienden a jugar varios titulos en sesiones cortas de tiempo.


A continuación, se crea una tabla de con los juegos que tienen más horas promedio jugadas.

```{r}

# Usar el dataframe 'Steam_2024_bestRevenue_1500'
top_ten_games <- lab %>%
  arrange(desc(avgPlaytime)) %>%  # Ordenar por avgPlayTime en orden descendente
  slice(1:10) %>%                  # Seleccionar los 10 primeros
  select(name, avgPlaytime) %>%    # Seleccionar solo las columnas 'name' y 'avgPlayTime'
  mutate(avgPlaytime = round(avgPlaytime, 2))  # Redondear a dos decimales

# Mostrar el resultado con kable
top_ten_games |> 
  kable(caption = "Los 10 juegos con más horas de juego") |> 
  kable_styling(full_width = F)

```




### Estudio de la variable DEVELOPERS


Ahora vamos a analizar la variable "developers". 
Realmente para nuestro estudio no es de gran importancia, aun así, crearemos una tabla de frecuencia para saber cuales son los 10 desarrolladores más frecuentes, ya que, puede ser curioso saberlo. 

```{r}

table(lab$developers) |> 
  # Convierte la tabla de frecuencias en un dataframe.
  as.data.frame() |> 
  
  arrange(desc(Freq)) |> 
  # Selecciona solo los 10 desarrolladores más frecuentes.
  slice(1:10) |> 
  # Añade una nueva columna 'F' calculando la frecuencia relativa acumulada.
  mutate(F = cumsum(Freq)/sum(Freq)) |> 
  # Convierte el dataframe resultante en una tabla 'gt' para formateo y estilización avanzados.
  gt() |>  
  
  # Añade un título en cursiva y negrita a la tabla de frecuencias
  tab_header(
    title = md("**_Los 10 desarrolladores más frecuentes_**")
  ) |>
  
  # Cambia las etiquetas de las columnas a notación matemática.
  cols_label(Var1 = "Desarrollador",  # Cambia 'Var1' a 'Desarrollador' (nombres individuales).
             Freq = "Frecuencia",  # Cambia 'Freq' a 'Frecuencia' (representando la frecuencia de cada valor).
             F = "Frecuencia relativa acumulada") |>  # Cambia 'F' al nombre completo en español.
  
  # Formatea los números a mostrar cuatro decimales.
  fmt_number(3, decimals = 4) |> 
  # Aplica un estilo de texto en negrita a la fila de encabezado de la tabla.
  tab_style(style = list(
    cell_text(weight = "bold")),  
    locations = cells_column_labels())


```

En la tabla podemos observar claramente los 10 desarrolladores más frecuentes entre los 1407 desarrolladores únicos.
Como ya hemos mencionado, esta variable no será de gran importancia a la hora de responder a nuestras preguntas y de cumplir nuestro objetivo final de la práctica.



### Box-plot

Ahora, emplearemos box-plots para examinar la dispersión y los valores atípicos en nuestras variables cuantitativas. Estos gráficos nos ofrecen una visión detallada de la distribución de los datos.

Utilizamos un box-plot para visualizar la distribución de la variable 'ph' en nuestro conjunto de datos, proporcionando una clara representación de la mediana, los cuartiles y los valores atípicos.

```{r}
# 'lab |> ggplot(aes(x= "ph", y = ph)) +' inicia una visualización ggplot2 usando el dataframe 'lab'.
lab |> 
  ggplot(aes(x= "ph", y = ph)) +  # Configura las estéticas del gráfico.
    # 'aes()' define cómo se asignarán variables a estéticas visuales en el gráfico.
    # 'x= "ph"' establece una constante para el eje x. 
    # 'y = ph' asigna la columna 'ph' del dataframe 'lab' al eje y.

  # 'geom_boxplot()' añade un gráfico de cajas al gráfico.
  # Esta función crea un diagrama de cajas que es útil para visualizar la distribución de una variable cuantitativa.
  geom_boxplot()+ 

  # 'theme_bw()' aplica un tema en blanco y negro para la visualización.
  # Este tema proporciona un fondo claro y líneas oscuras, lo que resulta en un gráfico con alto contraste y fácil de leer.
  theme_bw()

```


### Análisis numérico

Procedemos a realizar un análisis numérico detallado de nuestras variables, empleando estadísticas descriptivas para obtener una comprensión más profunda de los datos.

Calculamos estadísticas descriptivas para todas las variables numéricas en nuestro conjunto de datos, excluyendo la variable 'codigo'. Este paso nos proporciona un resumen numérico detallado de las características de los datos.

```{r}
lab |> select(where(is.numeric), -codigo) |>  # Selecciona solo las variables numéricas, excluyendo 'codigo'
  drop_na() |>  # Elimina filas con valores NA
    descr() # 'descr' es la función que se aplica. Calcula estadísticas descriptivas para todas las variables numéricas.
```


### Tipificación

En esta sección, nos enfocamos en la tipificación de nuestros datos, un proceso que nos permite estandarizar las variables y compararlas en una escala común.

Aquí, calculamos y examinamos los puntajes z para la variable 'ph'. Esto nos permite entender cómo se distribuyen los valores de 'ph' en relación con la media y la desviación estándar de la muestra.

```{r}
# 'z_ph <- scale(lab$ph)' calcula el puntaje z para la columna 'ph' del dataframe 'lab'.
z_ph <- scale(lab$ph)
  # 'scale()' es una función en R que estandariza los datos.
  # Resta la media y divide por la desviación estándar, resultando en datos con una media de 0 y una desviación estándar de 1.
  # Esto es útil para normalizar datos, especialmente en preparación para ciertos análisis estadísticos.

# 'mean(z_ph)' calcula la media de los puntajes z de 'ph'.
mean(z_ph)
```

Dado que los datos han sido estandarizados, la media debería ser muy cercana a 0. Esto verifica que la estandarización se ha realizado correctamente.
  
```{r}
# 'sd(z_ph)' calcula la desviación estándar de los puntajes z de 'ph'.
sd(z_ph)


```

La desviación estándar de los datos estandarizados debería ser cercana a 1. Esto también sirve como verificación de la estandarización.


### Discretización 

Finalmente, abordamos la discretización de nuestras variables, un método que nos permite convertir variables cuantitativas en categorías, facilitando ciertos tipos de análisis.

Comenzamos creando categorías para la variable 'est', dividiéndola en 8 intervalos. Luego, contamos la frecuencia de observaciones en cada intervalo para obtener una visión clara de cómo se distribuyen los valores de 'est'.

```{r}
# Transforma 'lab' creando una nueva columna 'clases_est' que clasifica 'est' en 8 intervalos
lab |> 
  mutate(clases_est = cut(est, breaks = 8)) |> 
  # Cuenta la frecuencia de cada clase en 'clases_est'
  count(clases_est)

# Utiliza 'knitr::kable' para crear una tabla formateada de la tabla de proporciones de 'imperfecciones'
knitr::kable(
  # Calcula la tabla de proporciones para la columna 'imperfecciones' en 'lab'
  prop.table(table(lab$imperfecciones)), 
  # Redondea los números a 4 decimales
  digits = 4
)

```

En este paso, generamos intervalos para 'ph' y creamos una tabla de frecuencias para estos intervalos, incluyendo la frecuencia relativa y acumulada.

```{r}
# Genera un histograma de la columna 'ph' del dataframe 'lab', pero no lo dibuja (plot = FALSE).
# El resultado se guarda en 'histo', que contiene, entre otros, los límites de los intervalos (breaks).
histo <- hist(lab$ph, plot = FALSE)

# Actualiza el dataframe 'lab' mediante 'mutate' para añadir una nueva columna 'clase'.
# 'cut' se utiliza para dividir la columna 'ph' en intervalos basados en los límites encontrados en 'histo$breaks'.
lab <- lab |> 
  mutate(clase = cut(ph, breaks = histo$breaks))

# Añade un nivel adicional "(6.4,6.45]" a los factores de la columna 'clase'.
# Esto es para incluir valores específicos que no estaban originalmente en los intervalos generados por 'hist' porque su suma es frecuencia es 0.
levels(lab$clase) <- c(levels(lab$clase), "(6.4,6.45]")

# Calcula la tabla de frecuencias para 'lab$clase' y la convierte en un dataframe.
tabla_frecuencias <- as.data.frame(table(lab$clase))

# Añade una columna para la frecuencia relativa (f) y los acumulados (N y F) redondeado a 0.
tabla_frecuencias <- tabla_frecuencias |> 
  mutate(
    f = round(Freq / sum(Freq), 4), # Frecuencia relativa redondeada a cuatro decimales
    N = cumsum(Freq),               # Frecuencia acumulada
    F = round(cumsum(f), 4)         # Frecuencia relativa acumulada redondeada a cuatro decimales
  )

# Usa 'flextable' para crear una tabla flexible a partir de 'tabla_frecuencias'.
flextable(tabla_frecuencias) |>
  # Personaliza los encabezados de la tabla.
   flextable::set_header_labels(
      Var1 = "Clase",
      Freq = "n",
      f = "Frecuencia Relativa",
      N = "Frecuencia Acumulada",
      F = "Frecuencia Relativa Acumulada"
  )


```





## Datos bivariantes

Ahora, exploraremos las relaciones bivariantes en nuestro conjunto de datos, observando cómo las variables interactúan entre sí. Esto incluye examinar las relaciones entre pares de variables tanto discretas como continuas.

### Tablas de contingencia: Variables discretas

Primero, analizaremos las variables discretas creando tablas de contingencia, que nos ayudarán a entender las relaciones entre distintas categorías.

Este código genera una tabla de contingencia absoluta entre 'analista' y 'tipo'. Nos permite ver cuántas veces cada tipo de queso ha sido analizado por cada analista.

```{r}
# Crea una tabla de contingencia absoluta entre las variables 'analista' y 'tipo' y la muestra en formato Markdown
kable(table(lab$analista, lab$tipo))
```

Aquí, creamos una tabla de contingencia que muestra las frecuencias relativas para las mismas variables, proporcionando una perspectiva porcentual de la relación entre 'analista' y 'tipo'.

```{r}
# Crea una tabla de contingencia relativa (frecuencias relativas) para las mismas variables y la muestra con dos decimales
kable(prop.table(table(lab$analista, lab$tipo)), digits = 2)
```

Este fragmento utiliza la función `ctable` del paquete 'summarytools' para crear una tabla de contingencia más avanzada, que nos dará una visión detallada de la frecuencia de cada combinación de 'tipo' y 'analista'.

```{r}
# Crea una tabla de contingencia usando la función 'ctable' del paquete 'summarytools'.
tabla_contingencia <- summarytools::ctable(lab$tipo, lab$analista)
  # 'summarytools::ctable' es una función del paquete 'summarytools' que se utiliza para crear tablas de contingencia.
  # 'lab$tipo' y 'lab$analista' son las dos variables del dataframe 'lab' que se están comparando.
  # La tabla de contingencia resultante mostrará la frecuencia de cada combinación de 'tipo' y 'analista'.

```

#### Distribuciones condicionadas

En esta subsección, nos centramos en las distribuciones condicionadas dentro de nuestra tabla de contingencia para obtener insights más específicos.

Este código filtra la tabla de contingencia para mostrar solo las entradas correspondientes a 'analista_13', permitiéndonos examinar de cerca los tipos de quesos que este analista ha revisado.

```{r}

# Selecciona la primera tabla de la lista 'tabla_contingencia', la convierte en un tibble y filtra por 'analista_13'.
tabla_contingencia[[1]] |> 
  # 'as_tibble()' convierte la tabla (que probablemente sea una matriz o dataframe) en un tibble, que es un tipo de dataframe moderno en R.
  as_tibble() |> 
  # 'filter(analista == 'analista_13')' filtra las filas donde la columna 'analista' es igual a 'analista_13'.
  filter(analista == 'analista_13')

```

Aquí, realizamos un filtrado similar para la variable 'tipo', centrándonos específicamente en el tipo 'A' para ver qué analistas han trabajado con este tipo de queso.

```{r}
# Selecciona la primera tabla de la lista 'tabla_contingencia', la convierte en un tibble y filtra por 'tipo == 'A''.
tabla_contingencia[[1]] |> 
  # 'as_tibble()' convierte la tabla en un tibble.
  as_tibble() |> 
  # 'filter(tipo == 'A')' filtra las filas donde la columna 'tipo' es igual a 'A'.
  filter(tipo == 'A')
```


### Tablas de contingencia: Variables continuas

Ahora, nos movemos hacia las variables continuas, transformándolas en categorías y examinando sus relaciones a través de tablas de contingencia.

Este fragmento de código primero determina los intervalos para las variables 'ph' y 'est' y luego crea una tabla de contingencia para estas variables categorizadas. La inclusión de totales nos proporciona una comprensión completa de cómo se distribuyen estas variables en relación con las demás.

```{r}
# Genera histogramas para las variables 'ph' y 'est' sin mostrar los gráficos, para determinar los intervalos de clase
histo <- hist(lab$ph, plot = FALSE)
histo2 <- hist(lab$est, plot = FALSE, breaks = 4)
# Clasifica las variables 'ph' y 'est' en categorías basadas en los intervalos anteriores y añade estas categorías al dataframe
lab <- lab |> 
  mutate(clase_ph = cut(ph, breaks = histo$breaks)) |> 
  mutate(clase_est = cut(est, breaks = histo2$breaks))
# Ajusta manualmente los niveles de la variable 'clase_ph' para incluir un intervalo específico
levels(lab$clase_ph) <- c(levels(lab$clase_ph), "(6.4,6.45]")

# Crea una tabla de contingencia entre las categorías de 'ph' y 'est', añadiendo totales con addmargins(), y la muestra
tabla <- table(lab$clase_ph, lab$clase_est) |> addmargins()
tabla |> kable()
```


### Covarianza y correlación

Finalmente, analizamos las relaciones numéricas entre variables mediante el cálculo de la covarianza y la correlación.

Este código calcula la matriz de covarianza para todas las variables numéricas en nuestro conjunto de datos, proporcionando una visión de cómo varían conjuntamente las variables.

```{r}
lab |> select(where(is.numeric), -codigo) |>  # Selecciona solo las variables numéricas, excluyendo 'codigo'
  drop_na() |>  # Elimina filas con valores NA
  cov() |>  # Calcula la matriz de covarianzas
  round(2)  # Redondea los resultados a 2 decimales
```

A continuación, calculamos y redondeamos la matriz de correlación para las mismas variables, que nos muestra la fuerza y la dirección de las relaciones lineales entre ellas.

```{r}
lab |> select(where(is.numeric), -codigo) |>  # Selecciona solo las variables numéricas, excluyendo 'codigo'
  drop_na() |>  # Elimina filas con valores NA
  cor() |>  # Calcula la matriz de correlación
  round(2)  # Redondea los resultados a 2 decimales
```

Finalmente, visualizamos la matriz de correlación usando el método de 'ellipse', lo que facilita la interpretación visual de estas correlaciones.

```{r}
# 'lab |> select(where(is.numeric), -codigo)' selecciona las columnas numéricas del dataframe 'lab', excluyendo la columna 'codigo'.
lab |> 
  select(where(is.numeric), -codigo) |> 
  # 'drop_na()' elimina todas las filas que contienen valores NA (faltantes).
  drop_na() |> 
  # 'cor()' calcula la matriz de correlación entre las columnas numéricas seleccionadas.
  cor() |> 
  # 'round(2)' redondea los coeficientes de correlación a dos decimales.
  round(2) |> 
  # 'corrplot()' visualiza la matriz de correlación.
  corrplot(
    method = "ellipse",  # 'method = "ellipse"' utiliza elipses para representar los coeficientes de correlación.
    type = "lower",      # 'type = "lower"' muestra solo la mitad inferior de la matriz de correlación.
    addCoef.col = "steelblue",  # 'addCoef.col = "steelblue"' establece el color de los coeficientes de correlación.
    diag = FALSE         # 'diag = FALSE' omite la diagonal principal de la matriz, que siempre es 1.
  )
```


### Gráficos de barras

En esta sección, utilizamos gráficos de barras para explorar las relaciones entre dos variables categóricas, 'tipo' y 'analista'. Estos gráficos nos permiten visualizar la frecuencia de cada categoría de manera efectiva.

Este gráfico de barras muestra la cantidad de cada tipo de queso analizado por cada analista, proporcionando una visión general de la distribución de los trabajos entre los analistas.

```{r}
# Gráficos de barras para frecuencias conjuntas
# Crea un gráfico de barras para las variables 'tipo' y 'analista' usando ggplot2
lab |> # Toma el dataframe 'lab'
  ggplot(aes(x = tipo, fill = analista)) + # Inicializa ggplot2, asignando 'tipo' al eje x y coloreando por 'analista'
  geom_bar() + # Añade un gráfico de barras, que por defecto cuenta la cantidad de cada 'tipo'
  theme_bw() # Aplica un tema en blanco y negro para una visualización más clara y profesional
```


Este código mejora el gráfico de barras anterior separando las barras para cada analista dentro de cada tipo de queso, lo que facilita comparar la carga de trabajo de los analistas para cada tipo.

```{r}
lab |> # Toma el dataframe 'lab'
  ggplot(aes(x = tipo, fill = analista)) + # Inicializa ggplot2, asignando 'tipo' al eje x y coloreando por 'analista'
  geom_bar(position = position_dodge()) + # Añade un gráfico de barras con barras separadas por 'analista' dentro de cada 'tipo'
  theme_bw() # Aplica un tema en blanco y negro para una visualización más clara y profesional
```

### Histogramas

Los histogramas nos ayudan a comprender la distribución de variables continuas. Aquí, exploramos la variable 'ph' en función de la categoría de 'tipo'.

Este histograma muestra la distribución del pH para diferentes tipos de queso, con colores distintos para cada tipo, lo que nos permite comparar visualmente cómo varía el pH entre los tipos.

```{r}
# Crear un histograma de 'ph' con colores basados en 'tipo'
ggplot(lab, aes(x = ph, fill = tipo)) +
  # Añadir la capa de histograma
  geom_histogram(
    bins = 15, 
    alpha = 0.7,  # Ajusta la transparencia para mejor visualización
    position = 'identity'  # Superpone las barras
  ) +
  # Definir los títulos de los ejes y el gráfico
  labs(
    title = "Histograma de pH por Tipo", 
    x = "pH", 
    y = "Frecuencia"
  ) +
  # Aplicar un tema
  theme_bw() +
  # Añadir leyenda (automáticamente generada por ggplot)
  guides(fill=guide_legend(title="Tipo"))
```


### Gráficos de dispersión

Los gráficos de dispersión son fundamentales para visualizar y entender las relaciones entre dos variables continuas.

Este gráfico muestra la relación entre 'est' y 'mg', proporcionando una visión general de cómo estas dos variables se relacionan en todo el conjunto de datos.

```{r}
# Gráfico de dispersión
# Crea un gráfico de dispersión para las variables 'est' y 'ph'
lab |> 
  # 'ggplot()' inicia una gráfica utilizando el paquete ggplot2. 'aes()' define las estéticas del gráfico, asignando 'est' al eje x y 'mg' al eje y.
  ggplot(aes(x = est, y = mg)) +
  # 'geom_point()' añade capas de puntos al gráfico, lo que crea un gráfico de dispersión con puntos representando las combinaciones de 'est' y 'mg'.
  geom_point()

```

Añadimos una línea de tendencia a nuestro gráfico de dispersión para resaltar la relación general entre 'est' y 'mg', lo que puede indicar la presencia de una correlación.

```{r}
# Gráfico de dispersión
# Crea un gráfico de dispersión para las variables 'est' y 'mg'
lab |> 
  # 'ggplot()' inicia una gráfica utilizando el paquete ggplot2. 'aes()' define las estéticas del gráfico, asignando 'est' al eje x y 'mg' al eje y.
  ggplot(aes(x = est, y = mg)) +
  # 'geom_point()' añade capas de puntos al gráfico, lo que crea un gráfico de dispersión con puntos representando las combinaciones de 'est' y 'mg'.
  geom_point() +
  # 'geom_smooth()' añade una línea de tendencia o ajuste al gráfico. Por defecto, realiza un ajuste de regresión lineal que muestra la tendencia general entre 'est' y 'mg'.
  geom_smooth(method = lm) +
  # 'labs()' permite personalizar las etiquetas del gráfico, como el título. Aquí se establece el título del gráfico.
  labs(title = "Gráfico de dispersión con ajuste de regresión")

```

Este gráfico mejora los anteriores al colorear los puntos según el tipo de queso y añadir una línea de ajuste, lo que nos permite ver cómo la relación entre 'est' y 'mg' varía entre los diferentes tipos. (Paradoja de Simpson)

```{r}
# Gráfico de dispersión
# Crea un gráfico de dispersión para las variables 'est' y 'ph'
lab |> 
  # 'ggplot()' inicia una gráfica utilizando el paquete ggplot2. 'aes()' define las estéticas del gráfico, asignando 'est' al eje x y 'mg' al eje y.  Además, la estética 'col' se usa para colorear los puntos según el valor de la variable 'tipo'.
  ggplot(aes(x = est, y = mg, col = tipo)) +
  # 'geom_point()' añade capas de puntos al gráfico, lo que crea un gráfico de dispersión con puntos representando las combinaciones de 'est' y 'mg'.
    geom_point() +
  # 'geom_smooth()' añade una línea de tendencia o ajuste al gráfico. Realiza un ajuste de regresión lineal que muestra la tendencia general entre 'est' y 'mg', para cada valor de la varaible tipo.
  geom_smooth(method = lm) +
  # 'labs()' permite personalizar las etiquetas del gráfico, como el título. Aquí se establece el título del gráfico.
  labs(title = "Gráfico de dispersión con ajuste de regresión")
```

### Box-plot

Los box-plots nos ofrecen una forma clara de ver la distribución de una variable continua entre diferentes categorías.

Este box-plot muestra la distribución del pH para diferentes tipos de queso, lo que nos ayuda a entender la variabilidad del pH en cada tipo.

```{r}
# Gráficos de cajas por grupos
lab |> 
  ggplot(aes(x = tipo, y = ph)) +  # Define las variables para el eje x ('tipo') y el eje y ('ph')
  geom_boxplot() +  # Crea un gráfico de cajas
  theme_bw() +  # Utiliza un tema en blanco y negro para el gráfico
  labs(title = "pH por tipo de queso")  # Añade un título al gráfico
```

Este código genera box-plots del pH para cada analista, añadiendo puntos individuales coloreados por tipo de queso, proporcionando una visión detallada de la variabilidad del pH según el analista y el tipo.

```{r}
# Gráficos de cajas por grupos eje y color 
lab |> 
  ggplot(aes(x = analista, y = ph)) +  # Establece 'analista' en el eje x y 'ph' en el eje y
  geom_boxplot() +  # Genera el gráfico de cajas
  geom_jitter(aes(col = tipo), alpha = 0.2) +  # Añade puntos individuales para mostrar la distribución, con color por 'tipo'
  theme_bw() +  # Aplica un tema en blanco y negro
  labs(title = "pH por analista")  # Asigna un título al gráfico
```

### Gráfico resumen

Este código crea una serie completa de gráficos bivariantes que muestran cómo cada par de variables seleccionadas ('ph', 'est', 'mg', 'sal') se relacionan entre sí, con una distinción de colores basada en la variable categórica 'tipo'. Es una manera eficiente de obtener una visión general de las relaciones entre múltiples variables en un conjunto de datos y es especialmente útil para identificar patrones, correlaciones y posibles anomalías.

```{r}
# 'ggpairs()' es una función del paquete GGally que crea pares de gráficos para cada combinación de variables.
ggpairs(
    # 'lab |> select(ph, est, mg, sal, tipo)' selecciona las columnas específicas 'ph', 'est', 'mg', 'sal' y 'tipo' del dataframe 'lab'.
    lab |> select(ph, est, mg, sal, tipo),
    # 'aes(col = tipo)' define las estéticas para el gráfico, en este caso, asignando diferentes colores a cada valor de 'tipo'.
    aes(col = tipo)
)
```

### Análisis numérico

Aquí, nos centramos en el análisis numérico para obtener estadísticas descriptivas de nuestro conjunto de datos.

#### Vector de medias

Calculamos la media de todas las variables numéricas en el conjunto de datos para obtener una visión general de las tendencias centrales.

```{r}
lab |>  select(where(is.numeric), -codigo) |>   # Selecciona todas las columnas numéricas menos el código
  drop_na() |>  # Elimina las filas con valores NA
  summarise(across(everything(), mean))  # Calcula la media para las columnas seleccionadas
```

#### Resumen numérico 

Este código proporciona un resumen estadístico detallado de la variable 'mg', desglosado por cada tipo de queso, lo que nos permite comparar las características de 'mg' entre los diferentes tipos.

```{r}
# Resumen numérico de una variable continua para cada categoría de otra discreta
# 'with(lab, stby(mg, tipo, descr))' aplica una función a un subconjunto de datos dentro del dataframe 'lab'.
with(
  # 'lab' es el dataframe que contiene los datos.
  lab, 
  # 'stby()' es una función que aplica otra función ('descr' en este caso) a subconjuntos de datos.
  # Aquí se aplica 'descr' a la variable 'mg', agrupada por los valores de 'tipo'.
  stby(
    # 'mg' es la variable a la que se le aplicará la función 'descr'.
    mg, 
    # 'tipo' es la variable de agrupación. 'descr' se aplicará por separado a los grupos definidos por 'tipo'.
    tipo, 
    # 'descr' es la función que se aplica. Calcula estadísticas descriptivas para 'mg' dentro de cada grupo de 'tipo'.
    descr
  )
)
```

### Regresión

Finalmente, utilizamos modelos de regresión lineal para explorar las relaciones entre variables continuas.

Este fragmento de código muestra un gráfico de dispersión de 'est' en función de 'mg' con una línea de regresión, resaltando la relación lineal entre estas variables.

```{r}
# Recta de refresión de la variable 'est' en función de 'mg'
lab |> 
  slice(1:15) |>  # Selecciona los primeros 15 registros
  select(mg, est) |>  # Selecciona las columnas 'mg' y 'est'
  ggplot(aes(x=mg, y = est)) +  # Define las variables para el gráfico
  geom_point() +  # Añade puntos al gráfico
  theme_bw() +  # Aplica un tema en blanco y negro
  geom_smooth(method = lm, se = FALSE)  # Añade una línea de regresión lineal sin intervalo de confianza
```

Este código crea un modelo lineal para predecir 'est' a partir de 'mg' y proporciona un resumen detallado del modelo, incluyendo estadísticas como el R-cuadrado y los coeficientes.

```{r}
# Creación y resumen de un modelo lineal para 'est' en función de 'mg'
mod <- lab |> 
  slice(1:15) |>  # Selecciona los primeros 15 registros
  select(mg, est) |>  # Selecciona las variables 'mg' y 'est'
  with(lm(est ~ mg))  # Crea un modelo lineal de 'est' en función de 'mg'

# Muestra un resumen del modelo lineal
# Esto incluye estadísticas como el R-cuadrado, los coeficientes del modelo, sus errores estándar, valores t y p-valores.
# Es útil para evaluar la calidad del ajuste y la significancia de las variables.
summary(mod)
```

Aquí, filtramos el conjunto de datos para incluir solo el tipo 'C' de queso y luego ajustamos un modelo lineal, lo que nos permite ver cómo la relación entre 'est' y 'mg' difiere para este tipo específico.

```{r}
# Recta de refresión de la variable 'est' en función de 'mg' filtrando por tipo 'C'
lab |> 
  # 'filter(tipo == "C")' filtra el dataframe para incluir solo las filas donde la columna 'tipo' es igual a "C".
  filter(tipo == "C") |> 
  # 'ggplot(aes(x = mg, y = est))' inicia la creación de un gráfico ggplot2, definiendo 'mg' como la variable del eje x y 'est' como la del eje y.
  ggplot(aes(x = mg, y = est)) +
  # 'geom_point()' añade una capa de puntos al gráfico, mostrando la relación entre 'mg' y 'est' para las observaciones donde 'tipo' es "C".
  geom_point() +
  # 'geom_smooth(method = "lm")' añade una línea de ajuste lineal al gráfico. 'method = "lm"' indica que se usa un modelo lineal para el ajuste.
  geom_smooth(method = "lm")

```

En esta parte del análisis, nos enfocamos en construir un modelo de regresión lineal para un subconjunto específico de nuestro conjunto de datos, permitiéndonos explorar la relación entre 'est' y 'mg' para un tipo particular de queso, proporcionando un resumen detallado del modelo.

```{r}
# 'modelo <- lm(est ~ mg, data = lab, subset = tipo == "C")' crea un modelo lineal.
modelo <- lm(
    # 'est ~ mg' define la fórmula del modelo, donde 'est' es la variable dependiente y 'mg' la variable independiente.
    est ~ mg, 
    # 'data = lab' especifica que los datos para el modelo provienen del dataframe 'lab'.
    data = lab, 
    # 'subset = tipo == "C"' restringe el análisis a las filas del dataframe donde 'tipo' es igual a "C".
    subset = tipo == "C"
)
# 'summary(modelo)' proporciona un resumen del modelo lineal ajustado.
# Esto incluye estadísticas como el R-cuadrado, los coeficientes del modelo, sus errores estándar, valores t y p-valores.
# Es útil para evaluar la calidad del ajuste y la significancia de las variables.
summary(modelo)
```

# Conclusiones 

El Análisis Exploratorio de Datos (EDA) en este laboratorio ha servido como marco de trabajo integral para aplicar y demostrar conceptos estadísticos esenciales. A través de este enfoque, hemos explorado y analizado los datos desde múltiples perspectivas, utilizando una variedad de técnicas y métodos estadísticos.

## Aplicación del EDA y sus Componentes

1. **Tablas de Frecuencias y Contingencia**: Dentro del marco del EDA, las tablas de frecuencias y de contingencia han proporcionado una visión inicial y fundamental de la distribución y las relaciones entre las variables categóricas en nuestros datos.

2. **Diversidad de Técnicas de Visualización**: Hemos empleado gráficos como histogramas, gráficos de barras, de dispersión y box plots para visualizar y comprender mejor las características de los datos. Cada tipo de gráfico ha aportado insights únicos, revelando distribuciones, relaciones y patrones clave.

3. **Medidas de Tendencia Central y Dispersión**: Como parte del EDA, la evaluación de la media, mediana, rango y desviación estándar ha sido crucial para resumir y describir las características centrales y la variabilidad de los datos.

4. **Identificación de Correlaciones y Modelado de Regresión**: El análisis de correlaciones y la aplicación de modelos de regresión lineal han sido fundamentales para entender la interacción entre variables, proporcionando una base para inferencias más profundas y predicciones.

5. **Enfoque Integral del EDA**: La implementación del EDA ha permitido un análisis sistemático y profundo del conjunto de datos, abarcando desde la identificación inicial de patrones y valores atípicos hasta la evaluación de relaciones complejas y tendencias.


En resumen, este laboratorio ha demostrado cómo los elementos teóricos de la estadística descriptiva pueden ser aplicados eficazmente para el análisis de datos. El EDA Nos permite no solo comprender los datos a un nivel superficial, sino también descubrir las historias y los patrones que yacen en su interior, preparando el terreno para análisis estadísticos más avanzados.
